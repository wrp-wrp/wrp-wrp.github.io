+++
date = '2025-12-22T15:41:00+08:00'
draft = false
math = true
title = 'WASM + Vector Index 端侧 ANNS 调研：量化就够了'
summary = "端侧 ANNS 调研：量化索引 + HNSW 图搜索 + 精确 Reranking 是简洁高效的架构，无需过度设计。"
tags = ["WASM", "向量检索", "ANNS", "量化", "HNSW"]
categories = ["技术调研"]
+++

# WASM + Vector Index 端侧 ANNS 调研

最近在简单调研一下 WASM + Vector Index 的工作，好像主要集中在浏览器端做 ANNS，于是开始大力调研，发现还真是（

## 背景：端侧 ANNS 的兴起

为了更快进行检索不远程调用搜索引擎的结果，砍掉这个网络延迟；也为了一些隐私考虑，一部分端侧 ANNS 搜索的研究开始展开了。由于索引的构建时间特别长，可能不很好研究，所以看起来主要都集中在"已经给你一个索引，如何进行更快的搜索"展开。

WASM 给算法的移植和高性能支持带来了方便，于是大家开始把 Vector Index 直接丢进 WASM，然后遇到了一个主要问题，就是浏览器和 WASM 都有比较强的内存限制。

## 内存限制问题

以浏览器为例：

| 场景 | 限制 |
|:---|:---|
| 传统 Float32 向量 | 480K 条 768 维向量 ≈ 1.4GB |
| 浏览器 Tab 内存限制 | 通常在 2-4GB |
| WASM 线性内存上限 | 4GB |

但是显然数据不存在内存里，访问就会慢，比如浏览器的 IndexedDB，速度就比内存慢不少。

看起来这个问题就是很标准的 **"小内存，外部存储访问慢的 ANNS"**，核心目标就是在不拖慢速度的条件下解决这个小内存的问题。

## 现有方案：WebANNS

于是，学术界出现了一些解决方案，比如 **WebANNS**，主张将向量部分存储在 IndexedDB 磁盘上，通过复杂的缓存策略和懒加载机制来节省内存：

- 在 search 的时候没加载到内存的点先不访问，先存着
- 然后一个 batch 一个 batch 这样批量取回来
- 还加入了一些额外的多级缓存

但是看看论文内容可以发现，**论文表示内存占用压缩到数据的 20% 的时候，P99 延迟提高了 40 倍**，这就感觉代价有点太大了。

## 一个简单的思路：量化就够了

所以一个想法是，这样复杂的从外面取向量的复杂机制真的有必要吗？

随着现在向量量化技术发展越来越好，比如 **RaBitQ** 的出现，看起来我直接把向量量化压缩以后直接存到内存里，先进行一个粗筛，最后拿着一堆 id 去外部存储把这些向量取回来 reranking，这样只会有一次批量的读取，无论还是读取次数还是读的 id 数量都比 WebANNS 类似的外部存储访问次数达到 $O(\text{ef})$ 的复杂机制好不少，只是 $O(1)$，还很容易实现。

## 三阶段流水线架构

所以类似 DiskANN 的结构，可以实现下面这个 pipeline，这个 pipeline 也没有像 DiskANN 那样优化外部存储的存储方式，只是简单从 IndexedDB 调用：

```
量化索引（全内存）→ 图搜索 → 批量读取原始向量 → 精确重排序
```

这个三阶段流水线的核心思想是：

| 策略 | 效果 |
|:---|:---|
| 用量化换内存 | Int8 量化实现 4x 压缩，Int4 可达 8x |
| 图搜索全在内存 | 消除遍历阶段的磁盘 IO |
| 仅候选向量走磁盘 | 批量读取 20-200 个向量用于精确重排序 |

## 实验验证

然后我就实现了这么一个库，看起来跑出来效果确实挺不错：

> 代码链接：[f3-wasm-demo](https://github.com/wrp-wrp/f3-wasm-demo)

做实验的时候由于 reranking 设置得比较多，可能甚至 recall 都比裸 HNSW 高一点，原论文可能认为自己的方法不影响 recall 而没有放出 recall，所以这里使用"可能"二字。

## 核心感想

感觉一个比较大的感想是，可能确实就是大部分场景下**量化对高维的 ANNS recall 影响就是不怎么大**，在小内存的情况下，内存上的收益比在 reranking 个数上的亏损大得多，或许直接这么简单量化的方法在小内存的场景就是最好的，进一步的压缩可能更应该倾向图索引本身的压缩或者干脆这种小内存场景直接用 IVFPQ。

并且考虑到 WASM 的推广，量化算法更加容易部署到计算核里去，根据用户场景自定义的设计看起来更简单了。

## 担忧：量化影响 recall？

感觉实测多 reranking 一点也没啥影响？让 AI 评价一下：

1. **高维空间的距离分布特点**：在高维空间中，向量之间的距离差异相对较小（维度灾难），这意味着 Top-K 候选的距离往往比较接近。

2. **量化误差可以被 Reranking 纠正**：只要量化后的近似搜索能找到「大致正确」的候选集，后续的精确距离重排序就能恢复准确的排序。

3. **HNSW 的容错性**：图索引本身就有一定的冗余，即使个别边的距离计算有误差，整体导航方向仍然大致正确。

## 结论：端侧 ANNS 不需要过度设计

在内存受限的端侧场景，仿照 DiskANN 的思路：

```
量化索引（全内存）+ HNSW 图搜索 + 精确 Reranking
```

这就是一种简洁、高效、好用的架构模式。

| 指标 | 表现 |
|:---|:---|
| ✅ 延迟 | 稳定在 10ms 级别 |
| ✅ Recall | 根据 reranking 数量几乎保持原状 |
| ✅ 工程复杂度 | 简单，易于维护 |
| ✅ 缓存策略 | 无需复杂的缓存调度策略 |

---

不过作为一只本科生小朋友感觉可能有一些没考虑到的点，但是作为一个研究这一方面的科研实习生，确实有点对 WebANNS 和类似想法的设计感到疑惑.jpg
